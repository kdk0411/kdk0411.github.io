---
layout: single
title:  "SL#02"
---

# 생존자 예측

# 데이터셋 정보 확인


```python
import pandas as pd
file_url = 'titanic.csv'
data = pd.read_csv(file_url)
data.head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Embarked</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>S</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>C</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>S</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>S</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>S</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 889 entries, 0 to 888
    Data columns (total 9 columns):
     #   Column    Non-Null Count  Dtype  
    ---  ------    --------------  -----  
     0   Pclass    889 non-null    int64  
     1   Name      889 non-null    object 
     2   Sex       889 non-null    object 
     3   Age       889 non-null    float64
     4   SibSp     889 non-null    int64  
     5   Parch     889 non-null    int64  
     6   Ticket    889 non-null    object 
     7   Embarked  889 non-null    object 
     8   Survived  889 non-null    int64  
    dtypes: float64(1), int64(4), object(4)
    memory usage: 62.6+ KB
    


```python
data.describe()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>889.000000</td>
      <td>889.000000</td>
      <td>889.000000</td>
      <td>889.000000</td>
      <td>889.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.311586</td>
      <td>29.315152</td>
      <td>0.524184</td>
      <td>0.382452</td>
      <td>0.382452</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.834700</td>
      <td>12.984932</td>
      <td>1.103705</td>
      <td>0.806761</td>
      <td>0.486260</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>22.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.000000</td>
      <td>35.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 데이터의 상관관계
data.corr()
```


<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Pclass</th>
      <td>1.000000</td>
      <td>-0.336512</td>
      <td>0.081656</td>
      <td>0.016824</td>
      <td>-0.335549</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>-0.336512</td>
      <td>1.000000</td>
      <td>-0.232543</td>
      <td>-0.171485</td>
      <td>-0.069822</td>
    </tr>
    <tr>
      <th>SibSp</th>
      <td>0.081656</td>
      <td>-0.232543</td>
      <td>1.000000</td>
      <td>0.414542</td>
      <td>-0.034040</td>
    </tr>
    <tr>
      <th>Parch</th>
      <td>0.016824</td>
      <td>-0.171485</td>
      <td>0.414542</td>
      <td>1.000000</td>
      <td>0.083151</td>
    </tr>
    <tr>
      <th>Survived</th>
      <td>-0.335549</td>
      <td>-0.069822</td>
      <td>-0.034040</td>
      <td>0.083151</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(data.corr()) # 상관관계를 이용하여 heatmap을 생성함
plt.show()
```
    
![output_6_1](https://github.com/kdk0411/kdk0411.github.io/assets/99461483/c89045c1-53c2-4f34-9990-92697fb78446)




    cmap='coolwarm'이라는 다른 색상으로 표현하는 방법이 있다고 하여
    한번 바꾸어 보겠습니다.


```python
sns.heatmap(data.corr(), cmap='coolwarm')
plt.show()
```

![output_8_1](https://github.com/kdk0411/kdk0411.github.io/assets/99461483/5eca6889-8c78-4dac-b825-5fca384dc369)
    


    현재 최대 1.0에서 최소 -0.2까지의 범위를 가지고 있는데 이를
    1 ~ -1로 조정해보겠습니다.
    또한 각 상관관계마다의 값도 출력하겠습니다.


```python
sns.heatmap(data.corr(), cmap='coolwarm', vmax=1,vmin=-1, annot=True)
plt.show()
```


![output_10_1](https://github.com/kdk0411/kdk0411.github.io/assets/99461483/71c60efd-9317-4e89-8248-6029e9286e74)



## 전처리 -> 범주형 변수 변환(One-Hot Encoding)

    One-Hot Encoding
        male과 female처럼 2진분류가 가능한 것을 숫자로 0or1로 표현하는 것을
        One-Hot Encoding이라고 한다.

    이 모델에 사용하는 csv에는 Name, Sex, Ticket, Embarked 이렇게 4가지의 Object가 있다.
    하지만 Name, Ticket은 학습에 도움이 되는 정보가 아니다.
    그렇기에 Sex, Embarked만을 이용하여 One-Hot Encoding을 진행하여 전처리 과정을 진행해보자.


```python
# Name, Ticket Object 제외
data = data.drop(['Name','Ticket'], axis=1)
```


```python
data.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Embarked</th>
      <th>Survived</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>S</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>C</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>S</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>S</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>S</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.get_dummies(data, columns=['Sex','Embarked'])
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Survived</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Embarked_C</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>884</th>
      <td>2</td>
      <td>27.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>885</th>
      <td>1</td>
      <td>19.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>886</th>
      <td>3</td>
      <td>28.0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>887</th>
      <td>1</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>888</th>
      <td>3</td>
      <td>32.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>889 rows × 10 columns</p>
</div>



    모델링 시에 이렇게 학습 시키면 계산량이 많아 모두 학습이 불가능 하다.
    그렇기에 drop_first=True를 이용하여 계산량을 줄여줄 것이다.
    이는 컬럼의 개수를 줄여주는 것이다.


```python
# 변경한 One-Hot Encoding을 적용
data = pd.get_dummies(data, columns=['Sex','Embarked'], drop_first = True)
```

## 모델링 및 예측


```python
from sklearn.model_selection import train_test_split

X = data.drop('Survived', axis = 1)
y = data['Survived']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)
```


```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train, y_train)

pred = model.predict(X_test)
```


```python
from sklearn.metrics import accuracy_score
accuracy_score(y_test, pred)
```




    0.7808988764044944



## Feature Engineering

    이 모델에서 사용한 csv를 자세히 살펴보면 SibSp와 Parch가 존재한다.
    이는 각각 형제/자매, 부모/자식을 의미한다.
    이를 Family로 합치면 One-Hot Encoding으로 하나의 0과 1로 표현이 가능할 것 같다.


```python
data['family'] = data['SibSp']+data['Parch']
data.drop(['SibSp', 'Parch'], axis=1, inplace=True)
data.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Pclass</th>
      <th>Age</th>
      <th>Survived</th>
      <th>Sex_male</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
      <th>family</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>22.0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>26.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>35.0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



    위와 같이 SibSp와 Parch가 Family로 합쳐진것을 볼 수 있다.
    그렇다면 다시 학습을 진행하여 예측을 해보겠다.


```python
X = data.drop('Survived', axis=1)
y = data['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)

model = LogisticRegression()

model.fit(X_train, y_train)

pred = model.predict(X_test)

accuracy_score(y_test, pred)
```




    0.7921348314606742

    정확도가 오르긴 하였지만 유의미한 증가라고 보기는 어렵다.
    하지만 이와 같이 csv 파일에서 유사한 값이 존재하면 합쳐 One-Hot Encoding으로
    계산이 용이한 값으로 변경해 주면 좋을 것 같다.
